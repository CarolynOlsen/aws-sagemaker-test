{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import boto3\n",
    "\n",
    "# Remove columns that have a STD less than\n",
    "MINIMUM_STD = 0.00001\n",
    "\n",
    "# Define columns\n",
    "DF_COLUMNS = [\"ENGINE_NUMBER\", \"TIME_IN_CYCLES\"] + \\\n",
    "             [\"OPERATIONAL_SETTING_{}\".format(x) for x in range(1,4)] + \\\n",
    "             [\"SENSOR_MEASUREMENT_{}\".format(x) for x in range(1,24)]\n",
    "\n",
    "# Define data paths and data names\n",
    "DATA_PATH = \"/home/ec2-user/SageMaker/aws-sagemaker-test/data/\"\n",
    "OUTDATA_PATH = \"/home/ec2-user/SageMaker/aws-sagemaker-test/engine_data/\"\n",
    "DS_FILENAME = DATA_PATH + \"{}_FD00{}.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining funcitons to load data and to filter out columns where STD is less than MINIMUM_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to load some data\n",
    "def load_data(data_path, filter_data=False):  \n",
    "    \"\"\"\n",
    "    Load data in\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_path, sep=' ', header=None, names=DF_COLUMNS)\n",
    "    data = data.drop(DF_COLUMNS[-2:], axis=1)\n",
    "#     data['TIME'] = pd.date_range('1/1/2000', periods=data.shape[0], freq='600s')\n",
    "    if filter_data:\n",
    "        data = drop_bad_columns(data)\n",
    "    return data\n",
    "\n",
    "def load_rul(data_path):  \n",
    "    df = pd.read_csv(data_path, header=None, names=['RUL'])\n",
    "    df['ENGINE_NUMBER'] = np.arange(1, len(df) + 1)\n",
    "    return df\n",
    "\n",
    "# Function to filter data that doesn't meet a certain criteria\n",
    "def drop_bad_columns(dataframe):\n",
    "    \"\"\"\n",
    "    Remove columns where the STD is less than MINIMUM_STD (only sensor data... not settings)\n",
    "    \"\"\"\n",
    "    df = dataframe.describe().T.reset_index()\n",
    "    for _,data in df.iterrows():\n",
    "        if abs(data['std']) <= MINIMUM_STD and 'SENSOR' in data['index']:\n",
    "            del dataframe[data['index']]\n",
    "    return dataframe.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train, test, RUL data for dataset 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset 1\n",
    "train001 = load_data(DS_FILENAME.format('train', '1'), filter_data=True)\n",
    "test001 = load_data(DS_FILENAME.format('test', '1'), filter_data=True)\n",
    "rul001 = load_rul(DS_FILENAME.format('RUL', '1'))\n",
    "\n",
    "# Load dataset 2\n",
    "train002 = load_data(DS_FILENAME.format('train', '2'), filter_data=True)\n",
    "test002 = load_data(DS_FILENAME.format('test', '2'), filter_data=True)\n",
    "rul002 = load_rul(DS_FILENAME.format('RUL', '2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rul(df):\n",
    "    # Get max cycle per engine\n",
    "    max_cycle = df.groupby('ENGINE_NUMBER').TIME_IN_CYCLES.max().reset_index()\n",
    "    max_cycle.columns = ['ENGINE_NUMBER', 'MAX_CYCLES']\n",
    "    \n",
    "    # Merge onto data and reorganize the columns\n",
    "    df = pd.merge(df, max_cycle, on='ENGINE_NUMBER')\n",
    "    df['RUL'] = df.MAX_CYCLES - df.TIME_IN_CYCLES\n",
    "    del df['MAX_CYCLES']\n",
    "    df = df[['RUL'] + [col for col in df.columns if col != 'RUL']]\n",
    "    del df['ENGINE_NUMBER']\n",
    "    return df\n",
    "\n",
    "\n",
    "train001 = compute_rul(train001)\n",
    "train002 = compute_rul(train002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_test_rul(test, rul):\n",
    "    # Only keep last row per engine number\n",
    "    df = test[test.groupby('ENGINE_NUMBER')['TIME_IN_CYCLES'].transform(max) == test['TIME_IN_CYCLES']]\n",
    "    df = pd.merge(df, rul, on='ENGINE_NUMBER')\n",
    "    df = df[['RUL'] + [col for col in df.columns if col != 'RUL']]\n",
    "    del df['ENGINE_NUMBER']\n",
    "    return df\n",
    "\n",
    "test001 = combine_test_rul(test001, rul001)\n",
    "test002 = combine_test_rul(test002, rul002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out new data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'bryan-predictive-maintenance'\n",
    "\n",
    "\n",
    "def write_to_csv(df, fname):\n",
    "    # Change column order and save file locally\n",
    "    df.to_csv(fname, index=False, header=False)\n",
    "    \n",
    "    # Create connection\n",
    "    s3conn = boto3.client('s3')\n",
    "    \n",
    "    # Write file\n",
    "    outfile = 'sagemaker/{}'.format(fname.split('/')[-1])\n",
    "    s3conn.put_object(\n",
    "            Body=open(fname),\n",
    "            Bucket=bucket,\n",
    "            Key=outfile\n",
    "        )\n",
    "    \n",
    "write_to_csv(train001, OUTDATA_PATH + 'train001.csv')\n",
    "write_to_csv(train002, OUTDATA_PATH + 'train002.csv')\n",
    "write_to_csv(test001, OUTDATA_PATH + 'test001.csv')   \n",
    "write_to_csv(test002, OUTDATA_PATH + 'test002.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python2",
   "language": "python",
   "name": "conda_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
